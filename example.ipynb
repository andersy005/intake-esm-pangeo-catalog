{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intake / Pangeo Catalog: Making It Easier To Consume Earth’s Climate and Weather Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Computer simulations of the Earth’s climate and weather generate huge amounts of data. These data are often persisted on high-performance computing (HPC) systems or in the cloud across multiple data assets in a variety of formats (netCDF, Zarr, etc.). \n",
    "Finding, investigating, and loading these data assets into compute-ready data containers costs time and effort. \n",
    "The user should know what data are available and their associated metadata, preferably before loading a specific data asset and analyzing it. \n",
    "\n",
    "In this notebook, we demonstrate [intake-esm](https://github.com/NCAR/intake-esm), a Python package and an [intake](https://github.com/intake/intake) plugin with aims of facilitating:\n",
    "\n",
    "- the discovery of earth's climate and weather datasets.\n",
    "- the ingestion of these datasets into [xarray](https://github.com/pydata/xarray) dataset containers.\n",
    "\n",
    "The common/popular starting point for finding and investigating large datasets is with a data catalog. \n",
    "A *data catalog* is a collection of metadata, combined with search tools, that helps data analysts and other users to find the data they need. \n",
    "For a user to take full advantage of intake-esm, they must point it to an *Earth System Model (ESM) data catalog*. \n",
    "This is a JSON-formatted file that conforms to the ESM collection specification.\n",
    "\n",
    "## ESM Collection Specification\n",
    "\n",
    "The [ESM collection specification](https://github.com/NCAR/esm-collection-spec) provides a machine-readable format for describing a wide range of climate and weather datasets, with a goal of making it easier to index and discover climate and weather data assets. \n",
    "An asset is any netCDF/HDF file or Zarr store that contains relevant data.\n",
    "\n",
    "An ESM data catalog serves as an inventory of available data, and provides information to explore the existing data assets. \n",
    "Additionally, an ESM catalog can contain information on how to aggregate compatible groups of data assets into singular xarray datasets. \n",
    "\n",
    "## Use Case: CMIP6 hosted on Google Cloud\n",
    "\n",
    "The Coupled Model Intercomparison Project (CMIP) is an international collaborative effort to improve the knowledge about climate change and its impacts on the Earth System and on our society. \n",
    "[CMIP began in 1995](https://www.wcrp-climate.org/wgcm-cmip), and today we are in its sixth phase (CMIP6). \n",
    "The CMIP6 data archive consists of data models created across approximately 30 working groups and 1,000 researchers investigating the urgent environmental problem of climate change, and will provide a wealth of information for the next Assessment Report (AR6) of the [Intergovernmental Panel on Climate Change](https://www.ipcc.ch/) (IPCC).\n",
    "\n",
    "Last year, Pangeo partnered with Google Cloud to bring CMIP6 climate data to Google Cloud’s Public Datasets program. \n",
    "You can read more about this process [here](https://cloud.google.com/blog/products/data-analytics/new-climate-model-data-now-google-public-datasets).\n",
    "For the remainder of this section, we will demonstrate intake-esm's features using the ESM data catalog for the CMIP6 data stored on Google Cloud Storage. \n",
    "This catalog resides [in a dedicated CMIP6 bucket](https://storage.googleapis.com/cmip6/pangeo-cmip6.json).\n",
    "\n",
    "### Loading an ESM data catalog\n",
    "\n",
    "To load an ESM data catalog with intake-esm, the user must provide a valid ESM data catalog as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "col = intake.open_esm_datastore('https://storage.googleapis.com/cmip6/pangeo-cmip6.json')\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary above tells us that this catalog contains over 268,000 data assets.\n",
    "We can get more information on the individual data assets contained in the catalog by calling the underlying dataframe created when it is initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data asset listed in the catalog contains:\n",
    "- the ambient aerosol optical thickness at 550nm (`variable_id='od550aer'`), as a function of latitude, longitude, time, and `member_id`,\n",
    "- in an individual climate model experiment with the Taiwan Earth System Model 1.0 model (`source_id='TaiESM1'`),\n",
    "- forced by the *Historical transient with SSTs prescribed from historical* experiment (`experiment_id='histSST'`),\n",
    "- developed by the Taiwan Research Center for Environmental Changes (`instution_id='AS-RCEC'`),\n",
    "- run as part of the Aerosols and Chemistry Model Intercomparison Project (`activity_id='AerChemMIP'`)\n",
    "\n",
    "And is located in Google Cloud Storage at `gs://cmip6/AerChemMIP/AS-RCEC/TaiESM1/histSST/r1i1p1f1/AERmon/od550aer/gn/`.\n",
    "\n",
    "### Searching for datasets\n",
    "\n",
    "After exploring the [CMIP6 controlled vocabulary](https://github.com/WCRP-CMIP/CMIP6_CVs), it’s straightforward to get the data assets you want using intake-esm's `search()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form query dictionary\n",
    "query = dict(experiment_id=['historical', 'ssp245', 'ssp585'],\n",
    "             table_id='Amon',\n",
    "             variable_id=['tas'],\n",
    "             member_id = 'r1i1p1f1',\n",
    "             grid_label='gr')\n",
    "\n",
    "# subset catalog and get some metrics grouped by 'source_id'\n",
    "col_subset = col.search(require_all_on=['source_id'], **query)\n",
    "col_subset.df.groupby('source_id')[['experiment_id', 'variable_id', 'table_id']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets\n",
    "\n",
    "Once you've identified data assets of interest, you can load them into xarray dataset containers using the `to_dataset_dict()` method. Invoking this method yields a Python dictionary of high-level aggregated xarray datasets. \n",
    "The logic for merging/concatenating the query results into higher level xarray datasets is provided in the input JSON file, under `aggregation_control`:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"aggregation_control\": {\n",
    "  \"variable_column_name\": \"variable_id\",\n",
    "  \"groupby_attrs\": [\n",
    "    \"activity_id\",\n",
    "    \"institution_id\",\n",
    "    \"source_id\",\n",
    "    \"experiment_id\",\n",
    "    \"table_id\",\n",
    "    \"grid_label\"\n",
    "  ],\n",
    "  \"aggregations\": [{\n",
    "      \"type\": \"union\",\n",
    "      \"attribute_name\": \"variable_id\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"type\": \"join_new\",\n",
    "      \"attribute_name\": \"member_id\",\n",
    "      \"options\": {\n",
    "        \"coords\": \"minimal\",\n",
    "        \"compat\": \"override\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"join_new\",\n",
    "      \"attribute_name\": \"dcpp_init_year\",\n",
    "      \"options\": {\n",
    "        \"coords\": \"minimal\",\n",
    "        \"compat\": \"override\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though these aggregation specifications are sufficient to merge individual data assets into xarray datasets, sometimes additional arguments must be provided depending on the format of the data assets.\n",
    "For example, Zarr-based assets can be loaded with the option `consolidated=True`, which relies on a consolidated metadata file to describe the assets with minimal data egress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = col_subset.to_dataset_dict(zarr_kwargs={'consolidated': True})\n",
    "\n",
    "# list all merged datasets\n",
    "[key for key in dsets.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the datasets have finished loading, we can extract any of them like we would a value in a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets['ScenarioMIP.THU.CIESM.ssp585.Amon.gr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pangeo Catalog\n",
    "\n",
    "Pangeo Catalog is an open-source project to enumerate and organize cloud-optimized climate data stored across a variety of providers. \n",
    "In addition to offering various useful climate datasets in a consolidated location, the project also serves as a means of accessing public ESM data catalogs.\n",
    "\n",
    "### Accessing catalogs using Python\n",
    "\n",
    "At the core of the project is a [GitHub repository](https://github.com/pangeo-data/pangeo-datastore) containing several static intake catalogs in the form of YAML files.\n",
    "Thanks to plugins like intake-esm and [intake-xarray](https://github.com/intake/intake-xarray), these catalogs can contain links to ESM data catalogs or data assets that can be loaded into xarray datasets, along with the arguments required to load them.\n",
    "\n",
    "By editing these files using Git-based version control, anyone is free to contribute a dataset supported by the available [intake plugins](https://intake.readthedocs.io/en/latest/plugin-directory.html).\n",
    "Users can then browse these catalogs by providing their associated URL as input into intake's `open_catalog()`; their tree-like structure allows a user to explore their entirety by simply opening the [root catalog](https://github.com/pangeo-data/pangeo-datastore/blob/master/intake-catalogs/master.yaml) and recursively walking through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml')\n",
    "entries = cat.walk(depth=5)\n",
    "\n",
    "[key for key in entries.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The catalogs can also be explored using intake's own `search()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subset = cat.search('cmip6')\n",
    "\n",
    "list(cat_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have found a dataset or collection we want to explore, we can do so without the need of any user inputted argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.climate.tracmip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing catalogs using catalog.pangeo.io\n",
    "\n",
    "For those who don't want to initialize a Python environmemt to explore the catalogs, [catalog.pangeo.io](https://catalog.pangeo.io/) offers a means of viewing them from a standalone web application.\n",
    "The website directly mirrors the catalogs in the GitHub repository, with previews of each dataset or collection loaded on the fly:\n",
    "\n",
    "<img src=\"images/pangeo-catalog.png\" alt=\"Example of an intake-esm collection on catalog.pangeo.io\" width=\"1000\">\n",
    "\n",
    "From here, users can view the JSON input associated with an ESM collection and sort/subset its contents:\n",
    "\n",
    "<img src=\"images/esm-demo.gif\" alt=\"Example of an intake-esm collection on catalog.pangeo.io\" width=\"800\">\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "With intake-esm, much of the toil associated with discovering, loading, and consolidating data assets can be eliminated.\n",
    "In addition to making computations on huge datasets more accessible to the scientific community, the package also promotes reproducibility by providing simple methodology to create consistent datasets.\n",
    "Coupled with Pangeo Catalog (which in itself is powered by intake), intake-esm gives climate scientists the means to create and distribute large data collections with instructions on how to use them essentially written into their ESM specifications.\n",
    "\n",
    "There is still much work to be done with respect to intake-esm and Pangeo Catalog; in particular, goals include:\n",
    "\n",
    "- Merging ESM collection specifications into [SpatioTemporal Asset Catalog (STAC) specification](https://stacspec.org/) to offer a more universal specification standard\n",
    "- Development of tools to verify and describe catalogued data on a regular basis\n",
    "- Restructuring of catalogs to allow subsetting by cloud provider region\n",
    "\n",
    "## References\n",
    "\n",
    "- [intake-esm documentation](https://intake-esm.readthedocs.io/en/latest/)\n",
    "- [intake documentation](https://intake.readthedocs.io/en/latest/)\n",
    "- [Pangeo Catalog on GitHub](https://github.com/pangeo-data/pangeo-datastore)\n",
    "- [Pangeo documentation](http://pangeo.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthcube-notebook]",
   "language": "python",
   "name": "conda-env-earthcube-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
